{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c977f226-16a6-48b1-a412-cd9ce0b30ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "Accuracy: 0.7467532467532467\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81        99\n",
      "           1       0.67      0.58      0.62        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.72      0.71      0.72       154\n",
      "weighted avg       0.74      0.75      0.74       154\n",
      "\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "Accuracy: 0.8688524590163934\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86        29\n",
      "           1       0.85      0.91      0.88        32\n",
      "\n",
      "    accuracy                           0.87        61\n",
      "   macro avg       0.87      0.87      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anujs\\OneDrive\\Desktop\\sample_project\\env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9875\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        52\n",
      "           2       0.97      1.00      0.98        28\n",
      "\n",
      "    accuracy                           0.99        80\n",
      "   macro avg       0.98      0.99      0.99        80\n",
      "weighted avg       0.99      0.99      0.99        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# Function to preprocess datasets and save encoders/scalers\n",
    "def preprocess_data(df, target_column, label_encoder_filename, scaler_filename, feature_filename):\n",
    "    # Handle missing values\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "        else:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    # Encode categorical features\n",
    "    label_encoders = {}\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    # Save label encoders\n",
    "    joblib.dump(label_encoders, label_encoder_filename)\n",
    "    \n",
    "    # Define features and target\n",
    "    \n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Save feature names\n",
    "    joblib.dump(list(X.columns), feature_filename)\n",
    "    \n",
    "    # Standardize numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Save scaler\n",
    "    joblib.dump(scaler, scaler_filename)\n",
    "    \n",
    "    return X_scaled, y\n",
    "\n",
    "# Function to train XGBoost model\n",
    "def train_xgb_model(X, y, model_filename):\n",
    "    # Split dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Define model\n",
    "    xgb_model = XGBClassifier(eval_metric='logloss', random_state=42, reg_lambda=1)\n",
    "    \n",
    "    # Hyperparameter tuning space\n",
    "    param_dist = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "    }\n",
    "    \n",
    "    # Adjust CV splits if data is too small\n",
    "    n_splits = min(5, len(set(y)))\n",
    "    \n",
    "    # Hyperparameter tuning\n",
    "    random_search = RandomizedSearchCV(\n",
    "        xgb_model, param_distributions=param_dist, n_iter=min(8, len(param_dist['n_estimators'])),\n",
    "        scoring='accuracy', cv=n_splits, verbose=1, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get best model\n",
    "    best_model = random_search.best_estimator_\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(best_model, model_filename)\n",
    "\n",
    "# Datasets\n",
    "datasets = [\n",
    "    (\"diabetes.csv\", \"Outcome\", \"diabetes_xgb.pkl\", \"diabetes_labels.pkl\", \"diabetes_scaler.pkl\", \"diabetes_features.pkl\"),\n",
    "    (\"heart.csv\", \"target\", \"heart_xgb.pkl\", \"heart_labels.pkl\", \"heart_scaler.pkl\", \"heart_features.pkl\"),\n",
    "    (\"kidney_disease.csv\", \"classification\", \"kidney_xgb.pkl\", \"kidney_labels.pkl\", \"kidney_scaler.pkl\", \"kidney_features.pkl\")\n",
    "]\n",
    "\n",
    "# Process each dataset\n",
    "for file, target, model_file, encoder_file, scaler_file, feature_file in datasets:\n",
    "    df = pd.read_csv(file)\n",
    "    X, y = preprocess_data(df, target, encoder_file, scaler_file, feature_file)\n",
    "    train_xgb_model(X, y, model_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75deb48-ebb1-4abb-816a-1454e6abd7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03498df-a9ec-4a26-a27d-c735ec5e79a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
